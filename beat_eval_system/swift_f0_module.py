import torch
import numpy as np
import os
import soundfile as sf
import torchaudio

# ============================================================
#  MODULE: SwiftF0
#  Chá»©c nÄƒng: TrÃ­ch xuáº¥t cao Ä‘á»™ (pitch/F0) nhanh vÃ  chÃ­nh xÃ¡c 
#  tá»« cÃ¡c Ä‘oáº¡n Ã¢m thanh giá»ng hÃ¡t, phá»¥c vá»¥ so sÃ¡nh giá»¯a máº«u gá»‘c 
#  (original) vÃ  báº£n thu cá»§a ngÆ°á»i dÃ¹ng (record).
#
#  Tham kháº£o:
#  https://github.com/w-okada/voice-changer/blob/main/Realtime-Voice-Clone/swift_pitch_extraction.py
# ============================================================


def load_audio_sf(audio_path):
    """
    Äá»c tá»‡p WAV báº±ng thÆ° viá»‡n `soundfile` Ä‘á»ƒ trÃ¡nh lá»—i codec cá»§a Torch trÃªn Windows.

    Äáº§u vÃ o:
        audio_path (str): Ä‘Æ°á»ng dáº«n tá»›i tá»‡p Ã¢m thanh (.wav)

    Äáº§u ra:
        tuple gá»“m:
            - waveform (torch.Tensor): dáº¡ng sÃ³ng Ã¢m [1, num_samples]
            - sr (int): táº§n sá»‘ láº¥y máº«u (sample rate)
    """
    y, sr = sf.read(audio_path)
    if y.ndim > 1:  # Náº¿u lÃ  stereo â†’ chuyá»ƒn sang mono
        y = np.mean(y, axis=1)
    waveform = torch.from_numpy(y).unsqueeze(0).float()
    return waveform, sr


def extract_pitch_swift(audio_path, hop_length=160, fmin=50.0, fmax=1100.0):
    """
    TrÃ­ch xuáº¥t cao Ä‘á»™ (F0) tá»« tá»‡p Ã¢m thanh báº±ng thuáº­t toÃ¡n SwiftF0 trong torchaudio.

    Äáº§u vÃ o:
        audio_path (str): Ä‘Æ°á»ng dáº«n tá»›i tá»‡p .wav
        hop_length (int): Ä‘á»™ dÃ i khung nháº£y (sá»‘ máº«u giá»¯a 2 khung)
        fmin (float): táº§n sá»‘ tháº¥p nháº¥t cÃ³ thá»ƒ phÃ¡t hiá»‡n (Hz)
        fmax (float): táº§n sá»‘ cao nháº¥t cÃ³ thá»ƒ phÃ¡t hiá»‡n (Hz)

    Äáº§u ra:
        np.ndarray: máº£ng giÃ¡ trá»‹ F0 cho tá»«ng khung thá»i gian (Ä‘Æ¡n vá»‹ Hz)
    """
    # --- 1. Äá»c Ã¢m thanh ---
    waveform, sr = load_audio_sf(audio_path)

    # --- 2. Ãp dá»¥ng SwiftF0 (torchaudio) ---
    pitch = torchaudio.functional.detect_pitch_frequency(
        waveform,
        sample_rate=sr,
        frame_time=hop_length / sr,
        freq_low=fmin,
        freq_high=fmax
    )

    # --- 3. Xá»­ lÃ½ khung im láº·ng ---
    pitch[pitch == 0] = np.nan  # thay 0 báº±ng NaN Ä‘á»ƒ dá»… nháº­n diá»‡n vÃ¹ng khÃ´ng cÃ³ tÃ­n hiá»‡u

    return pitch.squeeze().numpy()


def process_with_swiftf0(ref_path, user_path, output_dir="beat_eval_system/output"):
    """
    Thá»±c hiá»‡n toÃ n bá»™ quy trÃ¬nh trÃ­ch xuáº¥t pitch cho cáº£ máº«u gá»‘c vÃ  máº«u ngÆ°á»i dÃ¹ng.

    Äáº§u vÃ o:
        ref_path (str): Ä‘Æ°á»ng dáº«n tá»›i tá»‡p Ã¢m thanh gá»‘c (original.wav)
        user_path (str): Ä‘Æ°á»ng dáº«n tá»›i tá»‡p thu cá»§a ngÆ°á»i dÃ¹ng (record.wav)
        output_dir (str): thÆ° má»¥c lÆ°u trá»¯ káº¿t quáº£ (máº·c Ä‘á»‹nh: 'beat_eval_system/output')

    Äáº§u ra:
        tuple (f0_ref, f0_user): 
            - f0_ref: cao Ä‘á»™ máº«u gá»‘c (np.ndarray)
            - f0_user: cao Ä‘á»™ báº£n thu ngÆ°á»i dÃ¹ng (np.ndarray)
    """
    print("ğŸµ Äang trÃ­ch xuáº¥t cao Ä‘á»™ (SwiftF0)...")

    os.makedirs(output_dir, exist_ok=True)
    f0_ref = extract_pitch_swift(ref_path)
    f0_user = extract_pitch_swift(user_path)

    # --- 4. LÆ°u káº¿t quáº£ ---
    np.save(os.path.join(output_dir, "f0_ref.npy"), f0_ref)
    np.save(os.path.join(output_dir, "f0_user.npy"), f0_user)

    print("âœ… TrÃ­ch xuáº¥t pitch hoÃ n táº¥t. Káº¿t quáº£ Ä‘Æ°á»£c lÆ°u táº¡i thÆ° má»¥c output/: f0_ref.npy & f0_user.npy")

    return f0_ref, f0_user


# ============================================================
#  KIá»‚M THá»¬ MODULE TRá»°C TIáº¾P
# ============================================================
if __name__ == "__main__":
    f0_ref, f0_user = process_with_swiftf0(
        "beat_eval_system/output/preprocessed_original.wav",
        "beat_eval_system/output/preprocessed_record.wav"
    )
    print("F0 máº«u gá»‘c:", f0_ref[:10])
    print("F0 báº£n thu:", f0_user[:10])
